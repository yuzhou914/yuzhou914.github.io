<!DOCTYPE html>
<html>

<head lang="en">
    <link rel="icon" type="image/png" href="./img/icon.png">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <style>
        iframe {
            height: 75vh;
            width: 100%;
            /* or any width you prefer */
            border: none;
        }
    </style>

    <title>SmartEdit</title>
    <meta name="description" content="SmartEdit">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->
    <!--FACEBOOK-->
    <meta property="og:image" content="./img/milestone.jpg">
    <meta property="og:image:type" content="image/jpg">
    <meta property="og:image:width" content="2040">
    <meta property="og:image:height" content="638">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="http://ailab-cvc.github.io/seed"/>
    <meta property="og:title" content="SmartEdit" />
    <meta property="og:description" content="Project page for SmartEdit." />

    <!--TWITTER-->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="SmartEdit" />
    <meta name="twitter:description"
        content="Project page for SmartEdit." />
    <meta name="twitter:image" content="./img/milestone.jpg" />

    <!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
    <!-- Place favicon.ico in the root directory -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link rel="stylesheet" href="css/font.css">

    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script src="js/app.js"></script>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-52J0PM8XKV"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());
        gtag('config', 'G-52J0PM8XKV');
    </script>

    <!-- <link rel="stylesheet" href="css/bulma.min.css"> -->
    <link rel="stylesheet" href="css/bulma-carousel.min.css"> 
    <link rel="stylesheet" href="css/bulma-slider.min.css">
    <!-- <link rel="stylesheet" href="css/fontawesome.all.min.css"> -->
    <!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"> -->
    <link rel="stylesheet" href="css/index.css"> 

    <script src="js/jquery.min.js"></script>
    <script defer src="js/fontawesome.all.min.js"></script>
    <script src="js/bulma-carousel.min.js"></script>
    <script src="js/bulma-slider.min.js"></script>
    <script src="js/index.js"></script>

    <style>
        .nav-pills {
            position: relative;
            display: inline;
        }

        .author {
            position: relative;
            display: inline-block;
            border-bottom: 1px dotted black;
            /* If you want dots under the hoverable text */
        }

        /* Tooltip text */
        .author .affiliation {
            visibility: hidden;
            width: 120px;
            background-color: black;
            color: #fff;
            text-align: center;
            padding: 5px 0;
            border-radius: 6px;

            /* Position the tooltip text - see examples below! */
            position: absolute;
            z-index: 1;
            width: 120px;
            top: 100%;
            left: 50%;
            margin-left: -60px;
            /* Use half of the width (120/2 = 60), to center the tooltip */
        }

        /* Show the tooltip text when you mouse over the tooltip container */
        .author:hover .affiliation {
            visibility: visible;
        }

        .video-container {
            display: flex;
            flex-wrap: wrap;
            margin-top: 30px;
        }

        .video-wrapper {
            flex: 1;
            margin-right: 2px;
            margin-left: 2px;
            max-width: calc(33.33%px);
            /* 33.33% for 3 videos per row, subtracting margins */
            height: auto;
            text-align: center;
        }

        .video {
            max-width: 100%;
            height: auto;
        }

        .caption {
            margin-top: 0px;
        }

        .image-container {
            display: flex;
            flex-direction: row;
            /* Arrange items horizontally */
            justify-content: space-between;
            /* Spread items horizontally */
            align-items: flex-end;
            /* Align items at the bottom */
        }

        .image-container .image-wrapper {
            flex: 1;
            /* Distribute equal width to both images */
            padding: 10px;
            /* Add some spacing between images */
        }

        .image-container img {
            max-width: 100%;
            /* Constrain image width */
            height: auto;
            /* Maintain image aspect ratio */
            display: block;
            /* Remove extra space below inline images */
            margin: 0 auto;
            /* Center the images within their containers */
        }
    </style>
</head>





<!--从这里开始改.../-->
<!--https://yuzhou914.github.io/SmartEdit/-->
<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-14 text-center">
                <strong>
                    <font size="+4">&#127752; <span class="rainbow-gradient">SmartEdit</span>: Exploring Complex Instruction-based </font></br>
                    <font size="+4">Image Editing with Multimodal Large Language Models</font>
            </h2>
        </div>

    <div class="col-md-12 text-center">
        <span class="author-block">
          <a href="https://openreview.net/profile?id=~Yuzhou_Huang1">Yuzhou Huang*</a><sup>1,2</sup>,</span>

        <span class="author-block">
          <a href="https://liangbinxie.github.io/">Liangbin Xie*</a><sup>2,3,5</sup>,</span>

        <span class="author-block">
          <a href="https://xinntao.github.io">Xintao Wang</a><sup>2,4&#9993</sup>,</span>

        <span class="author-block">
          <a href="https://github.com/jiangyzy">Ziyang Yuan</a><sup>2,8</sup>,</span>

        <span class="author-block">
          <a href="https://vinthony.github.io/academic/">Xiaodong Cun</a><sup>4</sup>,</span>

        <span class="author-block">
          <a href="https://geyixiao.com/">Yixiao Ge</a><sup>2,4</sup>,</span>

        <span class="author-block">
          <a href="https://www.fst.um.edu.mo/personal/jtzhou/">Jiantao Zhou</a><sup>3</sup>,</span>

        <span class="author-block">
          <a href="https://scholar.google.com.hk/citations?user=OSDCB0UAAAAJ&hl=zh-CN">Chao Dong</a><sup>5,7</sup>,</span>

        <span class="author-block">
          <a href="https://sse.cuhk.edu.cn/en/faculty/huangrui">Rui Huang</a><sup>6</sup>,</span>

        <span class="author-block">
            <a href="http://zhangruimao.site/">Ruimao Zhang</a><sup>1&#9993</sup>,</span>

        <span class="author-block">
          <a href="https://scholar.google.com/citations?user=4oXBp9UAAAAJ">Ying Shan</a><sup>2,4</sup></span>

        <div class="content text-center">
            <span class="author-block"><sup>1</sup>School of Data Science, Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen, China,</span>
            <span class="author-block"><sup>2</sup>ARC Lab, Tencent PCG,</span>
            <span class="author-block"><sup>3</sup>University of Macau,</span>
            <span class="author-block"><sup>4</sup>Tencent AI Lab,</span>
            <span class="author-block"><sup>5</sup>Shenzhen Institute of Advanced Technology,</span>
            <span class="author-block"><sup>6</sup>School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen, China,</span>
            <span class="author-block"><sup>7</sup>Shanghai Artificial Intelligence Laboratory,</span>
            <span class="author-block"><sup>8</sup>Tsinghua University</span>

        </div>
            <a target="_blank" href="https://www.cuhk.edu.cn/en">
            <image src="assets/imgs/logo1-CUHKSZ.jpg" height="37px"> </a>
                &nbsp; &nbsp; &nbsp;
            <a target="_blank" href="https://arc.tencent.com/">
            <image src="assets/imgs/logo2-ARC.svg" height="80px"> </a>
    &nbsp; &nbsp; &nbsp;
            <a target="_blank" href="https://www.um.edu.mo/">
            <image src="assets/imgs/logo3-Macau.jpg" height="37px"> </a>

            <a target="_blank" href="https://ai.tencent.com/ailab/en/index">
            <image src="assets/imgs/logo4-TencentAI.jpg" height="37px"> </a>
                &nbsp; &nbsp; &nbsp;
            <a target="_blank" href="https://www.siat.ac.cn/">
            <image src="assets/imgs/logo5-SIAT.jpg" height="37px"> </a>
                &nbsp; &nbsp; &nbsp;
            <a target="_blank" href="https://www.shlab.org.cn/">
            <image src="assets/imgs/logo6-PJlab.jpg" height="37px"> </a>

            <a target="_blank" href="https://www.tsinghua.edu.cn/">
            <image src="assets/imgs/logo7-THU.jpg" height="37px"> </a>
 

    </div>
    <div class="col-md-8 col-md-offset-2">
        <div class="content text-align">
            <br>
            <p>
                <font size="+1">
                    We introduce <b>SmartEdit</b>, an instruction-based image editing method assisted by Multimodal Large Language Models, which aims at
                    exploring solutions on complex understanding and reasoning scenarios that are overlooked by previous works.
                    With the specialized design, our SmartEdit is capable of handling complex understanding
                    (the instructions that contain various object attributes like location, relative size, color, and in or outside the mirror) and reasoning scenarios.
                    <!--We proposed <b>CustomNet</b>, a zero-shot customization method that can generate harmonious-->
                </font>
            </p>
        </div>
    </div>


    <div class="col-md-8 col-md-offset-2">
        <h2 class="content text-center">
            <b>SmartEdit on Understanding Scenarios</b>
        </h2>
    </div>

    <div class="col-md-8 col-md-offset-2">
        <div class="image-container">
            <div class="image-wrapper">
                <img src="assets/imgs/SuppNew1.jpg" class="img-responsive", width="1000">
                <br>
            </div>
        </div>
    </div>

    <div class="col-md-8 col-md-offset-2">
        <h2 class="content text-center">
            <b>SmartEdit on Reasoning Scenarios</b>
        </h2>
    </div>

    <div class="col-md-8 col-md-offset-2">
        <div class="image-container">
            <div class="image-wrapper">
                <img src="assets/imgs/SuppNew2.jpg" class="img-responsive", width="1000">
                <br>
            </div>
        </div>
    </div>


<!--    <div class="col-md-8 col-md-offset-2">-->
<!--        <h2 class="content text-center">-->
<!--            <b>SmartEdit instruction editing results</b>-->
<!--        </h2>-->
<!--    </div>-->
<!--        <div class="container"> -->
<!--            <div class="col-md-10 col-md-offset-1 ">-->
<!--            <div id="results-carousel" class="carousel results-carousel">-->
<!--                <div class="item item-1 text-center">-->
<!--                <img src="assets/imgs/supp1.jpg", height="500", width="800">-->
<!--                </div>-->
<!--                <div class="item item-2 text-center">-->
<!--                <img src="assets/imgs/supp2.jpg", height="500", width="800">-->
<!--                </div>-->
<!--                </div>-->
<!--            </div>-->
<!--        </div>-->
<!--    </div>-->

    <div class="col-md-4 col-md-offset-4 text-center">
        <ul class="nav nav-pills nav-justified">
            <li>
                <a target="_blank" href="https://github.com/TencentARC/SmartEdit">
                    <image src="assets/imgs/github.png" height="60px">
                        <h4><strong>Github</strong></h4>
                </a>
            </li>

            <li>
                <a target="_blank" href="https://arxiv.org/abs/2310.19784">
                    <image src="assets/imgs/arxiv.png" height="60px">
                        <h4><strong>Paper</strong></h4>
                </a>
            </li>
        </ul>
    </div>


    <div class="col-md-8 col-md-offset-2 text-center">
        <h3>
            <b><font size="+5">Abstract</font></b>
        </h3>
    </div>
    <div class="col-md-8 col-md-offset-2">
        <p class="text-justify">
            Current instruction-based editing methods, such as InstructPix2Pix, often fail to produce satisfactory results in complex scenarios due to their dependence on the simple CLIP text encoder in diffusion models.
            To rectify this, this paper introduces SmartEdit, a novel approach to instruction-based image editing that leverages Large Language Models (LLMs) with visual inputs to enhance their understanding and reasoning capabilities.
            However, direct integration of these elements still faces challenges in situations requiring complex reasoning.
            To mitigate this, we propose a Bidirectional Interaction Module that enables comprehensive bidirectional information interactions between the input image and the MLLM output.
            During training, we initially incorporate perception data to boost the perception and understanding capabilities of diffusion models. Subsequently, we demonstrate that a small amount of complex instruction editing data can effectively stimulate SmartEdit's editing capabilities for more complex instructions.
            We further construct a new evaluation dataset, Reason-Edit, specifically tailored for complex instruction-based image editing.
            Both quantitative and qualitative results on this evaluation dataset indicate that our SmartEdit surpasses previous methods, paving the way for the practical application of complex instruction-based image editing.
        </p>
    </div>


    <div class="col-md-8 col-md-offset-2 text-center">
        <h3>
            <b><font size="+5">SmartEdit framework</font></b>
        </h3>
    </div>

    <div class="col-md-8 col-md-offset-2">
        <div class="image-container">
            <div class="image-wrapper">
                <img src="assets/imgs/2-SmartEdit.jpg" class="img-responsive", width="1000">
            </div>
        </div>
    </div>

    <div class="col-md-8 col-md-offset-2">
        <p class="text-justify">
            The overall framework of SmartEdit,
            which is an instruction-based image editing model that leverages MultiModal Large Language Models (MLLMs)
            with visual inputs to enhance their understanding and reasoning capabilitie.
        </p>
    </div>


    <div class="col-md-8 col-md-offset-2 text-center">
        <h3>
            <b><font size="+3">Comparisons on Understanding Scenarios </font></b>
        </h3>
    </div>

    <div class="col-md-8 col-md-offset-2">
        <div class="image-container">
            <div class="image-wrapper">
                <img src="assets/imgs/3-Understanding.jpg" class="img-responsive", width="1000">
            </div>
        </div>
    </div>

    <div class="col-md-8 col-md-offset-2">
        <p class="text-justify">
            Qualitative comparison on complex understanding scenarios.
            Compared to other methods, SmartEdit can precisely edit specific objects in images according to instructions,
            while keeping the content in other areas unchanged.
        </p>
    </div>


    <div class="col-md-8 col-md-offset-2 text-center">
        <h3>
            <b><font size="+3">Comparisons on Reasoning Scenarios </font></b>
        </h3>
    </div>

    <div class="col-md-8 col-md-offset-2">
        <div class="image-container">
            <div class="image-wrapper">
                <img src="assets/imgs/4-Reasoning.jpg" class="img-responsive", width="1000">
            </div>
        </div>
    </div>

    <div class="col-md-8 col-md-offset-2">
        <p class="text-justify">
            Qualitative comparison on reasoning scenarios.
            For reasoning scenarios,
            SmartEdit can effectively utilize the reasoning capabilities of the LLM to identify the corresponding objects,
            and then edit the objects according to the instructions.
            Other methods perform poorly in these scenarios.
        </p>
    </div>


    <div class="col-md-8 col-md-offset-2 text-center">
        <h3>
            <b><font size="+3">MagicBrush Results </font></b>
        </h3>
    </div>

    <div class="col-md-8 col-md-offset-2">
        <div class="image-container">
            <div class="image-wrapper">
                <img src="assets/imgs/5-MagicBrush.jpg" class="img-responsive", width="1000">
            </div>
        </div>
    </div>

    <div class="col-md-8 col-md-offset-2">
        <p class="text-justify">
            The performance of SmartEdit on the MagicBrush test dataset.
            SmartEdit has good editing effects on the MagicBrush test dataset,
            not only for single-turn but also for multi-turn.
        </p>
    </div>


    <div class="col-md-8 col-md-offset-2 text-center">
        <h3>
            <b><font size="+5">Citation</font></b>
        </h3>
    </div>

    <div class="row">
        <div class="col-md-8 col-md-offset-2">
            <pre><code>@misc{huang2023smartedit,
                title={SmartEdit: Exploring Complex Instruction-based Image Editing with Multimodal Large Language Models},
                author={Yuzhou Huang and Liangbin Xie and Xintao Wang and Ziyang Yuan and Xiaodong Cun and Yixiao Ge and Jiantao Zhou and Chao Dong and Rui Huang and Ruimao Zhang and Ying Shan},
                year={2023},
                eprint={2310.19784},
                archivePrefix={arXiv},
                primaryClass={cs.CV}
          }</code></pre>
        </div>
    </div>
</div>
</body>
</html>
